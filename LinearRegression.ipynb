{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "This project is based predicting car fuel effeciency with a model trained on current data.\n",
    "\n",
    "There are several steps involved in it I have a decent amount of data which I got from https://www.fueleconomy.gov/feg/download.shtml which contains information related to cars and there mpg(miles per gallon).\n",
    "\n",
    "The problem with this data is although it is excel sheet and csv file. There is still a small amount of incononsistencies in the data. \n",
    "\n",
    "Our first few steps will involve making our data uniform and properly labelled, so that our model can easily and effectively train on the model.\n",
    "\n",
    "Right now I have data from 2000 till 2025. The first problem involves, how can I make the data in a uniform file format, because our data is in mixed files.\n",
    "\n",
    "Since the majority of data files are in excel format. I will go ahead and make the other .csv files to .xlsx files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the bellow cell, we will convert all the .csv files to .xlsx files in order to achieve uniform file format for our data\n",
    "csv_directory = 'Data/'\n",
    "\n",
    "for filename in os.listdir(csv_directory):\n",
    "    if filename.endswith('.csv'):\n",
    "        \n",
    "        csv_file = os.path.join(csv_directory, filename)\n",
    "        df = pd.read_csv(csv_file, on_bad_lines='skip')\n",
    "\n",
    "        \n",
    "        \n",
    "        excel_file = os.path.join(csv_directory, filename.replace('.csv', '.xlsx'))\n",
    "\n",
    "        df.to_excel(excel_file, index=False)\n",
    "        print(f'Converted {filename} to {excel_file}')\n",
    "\n",
    "        os.remove(csv_file)\n",
    "        print(f'Deleted {csv_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is visible from the above output that all the files has been converted, now we will proceed with our next inconsistency which is our file names. As you can see all the files have long and different names, which might become a peoblem when we will merge them into one (This is only an assumption). I think the better way to change the names of our file will be if we name it with the year's data it consist. I will try my best to keep this automated but looking at some files. It is not possible, so after automated task, I will perform the remaining manually.\n",
    "\n",
    "If we notice the patteren most of the recent files follow the same pattren in their names, which will be very helpful to automate the task. The name provide too much information like; release date, etc. This information is not of any use for our application. The only thing we need is year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2014.xlsx', '2009.xlsx', '2016.xlsx', '2022.xlsx', '2020.xlsx', '2019.xlsx', '2007.xlsx', '2001.xlsx', '2008.xlsx', '2023.xlsx', '2021.xlsx', '2017.xlsx', '2011.xlsx', '2015.xlsx', '2003.xlsx', '2013.xlsx', '2004.xlsx', '2002.xlsx', '2018.xlsx', '2012.xlsx', '2024.xlsx', '2006.xlsx', '2025.xlsx', '2005.xlsx', '2010.xlsx']\n"
     ]
    }
   ],
   "source": [
    "# in the below method we will change the file names for our convinience to work with simplified data\n",
    "\n",
    "for file in os.listdir(\"Data/\"):\n",
    "    original = file\n",
    "    file, extention = file.split(\".\")\n",
    "    file = file.replace(\"_\",\"-\")\n",
    "    file = file.split(\"-\")\n",
    "    file = file[0].split()\n",
    "    file = file[0]\n",
    "    os.rename(\"Data/\"+original, \"Data/\"+file+\".\"+extention)\n",
    "    \n",
    "print(os.listdir(\"Data/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After changing the appearance of our files. There is another problem with the data which needs to be addressed. We need a model column in our spreadsheet, which will specify the year in which the car was manufactured. The problem is that all the files before 2010 don't have that column. This issue can be resolved manually and it will not take much time but I think an automated approach will be right way to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "folder_path = 'Data/'\n",
    "\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".xlsx\"):  \n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        df = pd.read_excel(file_path)\n",
    "        \n",
    "        if 'Model Year' in df.columns:\n",
    "            df.rename(columns={'Model Year': 'model'}, inplace=True)\n",
    "        elif 'Model Yr' in df.columns:\n",
    "            df.rename(columns={'Model Yr': 'model'}, inplace=True)\n",
    "        elif 'model' not in df.columns:\n",
    "            df.insert(0, 'model', filename.removesuffix(\".xlsx\")) \n",
    "\n",
    "        if df.columns[0] != 'model':\n",
    "            cols = ['model'] + [col for col in df.columns if col != 'model']\n",
    "            df = df[cols]  \n",
    "\n",
    "        df.to_excel(file_path, index=False)\n",
    "\n",
    "        print(f'Processed {filename}: \"model\" column added or moved to the first position.')\n",
    "\n",
    "print(\"Process completed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code i just added the model year in the files which did not have that. Also made it uniform in all the files. So that in future it will be easy for me to work with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step is gathering all the data in a single file but the problem is that there is no consistent headers for each column in our .xlsx files. Fortunetly we have a solution to this. I will be using dictionaries in python where i will mention all the instances of same header and give them a standard and than i will store all the data in a new file and after that our data will be ready to built a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully consolidated and sorted by Model year into 'Cleaned_Data.xlsx'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "\n",
    "column_mapping = {\n",
    "    'model': 'Model',\n",
    "    'Manufacturer': 'Manufacturer',\n",
    "    'MFR': 'Manufacturer',\n",
    "    'Mfr Name': 'Manufacturer',\n",
    "    'carline name': 'Carline',\n",
    "    'CAR LINE': 'Carline',\n",
    "    'Carline': 'Carline',\n",
    "    'cyl': 'cyl',\n",
    "    'NUMB CYL': 'cyl',\n",
    "    '# Cyl': 'cyl',\n",
    "    'trans': 'Transmission',\n",
    "    'TRANS': 'Transmission',\n",
    "    'Trans as listed in FE Guide (derived from col AA thru AF)': 'Transmission',\n",
    "    'Trans in FE Guide (MFR entered for data entered after May 13 2011)': 'Transmission',\n",
    "    'Transmission': 'Transmission',\n",
    "    'cty': 'cty',\n",
    "    'CITY MPG (GUIDE)': 'cty',\n",
    "    'City FE (Guide) - Conventional Fuel': 'cty',\n",
    "    'hwy': 'hwy',\n",
    "    'HWY MPG (GUIDE)': 'hwy',\n",
    "    'Hwy FE (Guide) - Conventional Fuel': 'hwy',\n",
    "    'cmb': 'cmb',\n",
    "    'COMB MPG (GUIDE)': 'cmb',\n",
    "    'Comb FE (Guide) - Conventional Fuel': 'cmb',\n",
    "    'displ': 'Engine_Size',\n",
    "    'DISPLACEMENT': 'Engine_Size',\n",
    "    'Eng Displ': 'Engine_Size'\n",
    "}\n",
    "\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "for file in glob.glob(\"Data/*.xlsx\"): \n",
    "    df = pd.read_excel(file, engine='openpyxl')\n",
    "\n",
    "    df = df.rename(columns={col: column_mapping[col] for col in df.columns if col in column_mapping})\n",
    "    standardized_df = df.reindex(columns=['Model', 'Manufacturer', 'Carline', 'cyl', 'Transmission', 'cty', 'hwy', 'cmb', 'Engine_Size'])\n",
    "    data_frames.append(standardized_df)\n",
    "\n",
    "final_df = pd.concat(data_frames, ignore_index=True)\n",
    "final_df = final_df.sort_values(by='Model', ascending=True)\n",
    "final_df.to_excel('Data/Cleaned_Data.xlsx', index=False)\n",
    "\n",
    "print(\"Data successfully consolidated and sorted by Model year into 'Cleaned_Data.xlsx'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the running the above cell our data is finally cleaned and move to one data file. Now we should be able to train our model with this data but before developing a model we will look at our data visually in form of graphs, which will make us understand the patterns and according to these patterns we will decide which model is suitable for this application.\n",
    "\n",
    "In the below cells we are going to look at our data and try to understand what do we have by looking at it with different techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27863, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will see how many rows and columns do we have\n",
    "df = pd.read_excel('Data/Cleaned_Data.xlsx')\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 27863 rows and 9 columns. Lets print the header of each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        Model         Manufacturer            Carline  cyl Transmission   cty  \\\n",
       "0       2001               SUZUKI  VITARA 2-DOOR 4WD  4.0     Auto(L4)  24.0   \n",
       "1       2001               SUZUKI  VITARA 2-DOOR 4WD  4.0   Manual(M5)  25.0   \n",
       "2       2001               SUZUKI  VITARA 2-DOOR 4WD  4.0     Auto(L4)  23.0   \n",
       "3       2001               SUZUKI  VITARA 2-DOOR 4WD  4.0   Manual(M5)  22.0   \n",
       "4       2001               SUZUKI  VITARA 4-DOOR 4WD  4.0     Auto(L4)  23.0   \n",
       "...      ...                  ...                ...  ...          ...   ...   \n",
       "27858   2025  Volkswagen Group of         A8 quattro  6.0     Auto(S8)  20.0   \n",
       "27859   2025        Mercedes-Benz       E 450 4MATIC  6.0     Auto(A9)  22.0   \n",
       "27860   2025              Hyundai         Sonata FWD  4.0  Auto(AM-S8)  23.0   \n",
       "27861   2025                Honda     INTEGRA A-SPEC  4.0  Auto(AV-S7)  29.0   \n",
       "27862   2025                Honda            INTEGRA  4.0   Manual(M6)  21.0   \n",
       "\n",
       "        hwy   cmb  Engine_Size  \n",
       "0      27.0  25.0          1.6  \n",
       "1      27.0  26.0          1.6  \n",
       "2      25.0  24.0          2.0  \n",
       "3      24.0  23.0          2.0  \n",
       "4      25.0  24.0          2.0  \n",
       "...     ...   ...          ...  \n",
       "27858  26.0  22.0          3.0  \n",
       "27859  31.0  25.0          3.0  \n",
       "27860  32.0  27.0          2.5  \n",
       "27861  36.0  32.0          1.5  \n",
       "27862  28.0  24.0          2.0  \n",
       "\n",
       "[27863 rows x 9 columns]>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see we have first 5 and last five records of our data and the headers. Now lets try to see how many different manufacturers we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUZUKI' 'TOYOTA' 'OLDSMOBILE' 'PONTIAC' 'SUBARU' 'MITSUBISHI' 'NISSAN'\n",
      " 'AUDI' 'BMW' 'CHEVROLET' 'JAGUAR' 'MERCEDES-BENZ' 'PORSCHE' 'PLYMOUTH'\n",
      " 'GMC' 'DODGE' 'FERRARI' 'R-R MTR CARS LTD.' 'SAAB' 'IMPCO' 'LEXUS'\n",
      " 'HONDA' 'LAMBORGHINI' 'MAZDA' 'VOLKSWAGEN' 'BENTLEY' 'FORD' 'HYUNDAI'\n",
      " 'DAEWOO' 'CHRYSLER' 'SATURN' 'KIA' 'LINCOLN-MERCURY' 'INFINITI' 'VOLVO'\n",
      " 'ACURA' 'BUICK' 'CADILLAC' 'ISUZU' 'MERCURY' 'JEEP' 'LAND ROVER'\n",
      " 'LINCOLN' 'MASERATI' 'QUANTUM' 'ROUSH PERFORMANCE' 'ASTON MARTIN' 'GM'\n",
      " 'ALPINA' 'LOTUS' 'MORGAN' 'MINI' 'ROLLS-ROYCE' 'HUMMER' nan 'SPYKR'\n",
      " 'SHLBY' 'SALEEN PERFORMANCE' 'TCSTR' 'BUGATTI' 'VW' 'Pontiac' 'Toyota'\n",
      " 'Audi' 'aston martin' 'Mercedes-Benz' 'Nissan' 'Bentley' 'Bugatti'\n",
      " 'FOMOCO' 'Mitsubishi Motors Co' 'Porsche' 'Chrysler Group LLC'\n",
      " 'Volkswagen' 'Volvo' 'Honda' 'Hyundai' 'Subaru' 'Suzuki' 'Kia'\n",
      " 'Mitsubishi Motors NA' 'NUMMI' 'Jaguar Cars' 'Rolls-Royce' 'Maserati'\n",
      " 'Ferrari' 'GDX' 'Roush' 'Spyker' 'Lamborghini' 'Lotus' 'Land Rover'\n",
      " 'General Motors' 'Ford Motor Company' 'Saab Cars North America'\n",
      " 'Mahindra' 'VPG' 'Jaguar Land Rover L' 'McLaren Automotive '\n",
      " 'Mobility Ventures L' 'Pagani Automobili S' 'FCA US LLC'\n",
      " 'Volkswagen Group of' 'Quantum Fuel System' 'McLaren Automotive'\n",
      " 'FCA Italy' 'Koenigsegg' 'RUF' 'SUBARU TECNICA INTE' 'Pagani S.p.A.'\n",
      " 'Ineos Automotive Li']\n",
      "111\n"
     ]
    }
   ],
   "source": [
    "manufacturers = df['Manufacturer'].unique()\n",
    "print(manufacturers)\n",
    "print(len(manufacturers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 111 manufacturers in our data. Now we are going to print the Carline of a perticular manufacturer. lets say SUZUKI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Carline\n",
      "0     VITARA 2-DOOR 4WD\n",
      "1     VITARA 2-DOOR 4WD\n",
      "2     VITARA 2-DOOR 4WD\n",
      "3     VITARA 2-DOOR 4WD\n",
      "4     VITARA 4-DOOR 4WD\n",
      "...                 ...\n",
      "9432            XL7 FWD\n",
      "9607   GRAND VITARA 4WD\n",
      "9608   GRAND VITARA 4WD\n",
      "9609   GRAND VITARA 4WD\n",
      "9610            XL7 AWD\n",
      "\n",
      "[203 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "suzuki_cars = df[df['Manufacturer'] == 'SUZUKI']\n",
    "print(suzuki_cars[['Carline']]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it can be seen with above techniques we can know more about our data and customize is accordingly in order to find the right model for prediction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "This is the end of first iteration. The goal of this iteration was get fimiliar with how to refine and make a useable data. With Pandas it was fairly easy and there was a learning curve for me as well because I got to work with these technologies for the first time.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
